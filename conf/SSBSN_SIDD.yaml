
model: 
  type: SSBSN
  kwargs:
    pd_a: 0
    pd_b: 0
    pd_pad: 0
    R3: True
    R3_T: 8
    R3_p: 0.16
    bsn: SSBSNl
    in_ch: 1
    bsn_base_ch: 128
    bsn_num_module: 9
    mode: [na, na, na, na, na, na, ss, ss, ss]
    f_scale: 2
    ss_exp_factor: 1
    
model_input: [noisy] # e.g.) real_noisy, syn_noisy, clean

trainer: Trainer

training:
  dataset: prep_SIDD

  dataset_args:
    add_noise: uni-0.2 # e.g.) None bypass uni-15. gau-15. gau_blind-10.:50. het_gau-10.:50. see more detail in denoise_dataset.py
    crop_size: None
    aug: None
    n_repeat: 1
    dataset_dir: 'K:\\mydata\\different private gradient\\FasionMNIST_grad\\train'
  
  batch_size: 1

  max_epoch: 20
  
  init_lr: 1e-4
  scheduler:
    type: step
    step:
      step_size: 16
      gamma: 0.1
  loss: 1*self_L1
  tmp_info: []
  optimizer:
    type: Adam
    Adam:
      betas: [0.9, 0.999]

  warmup: False
  warmup_iter: 200

validation:
  dataset: SIDD_val

  dataset_args:
    crop_size: None # [64, 64]
    add_noise: gau-0.010859 # e.g.) None uni-15. gau-15. gau_blind-10.:50. poi_gau-10.:50.
    n_data: 64
    dataset_dir: 'K:\mydata\different private gradient\FasionMNIST_grad\val'

  add_con: 0.5
  floor: True

  val: False
  save_image: True
  
  start_epoch: 1
  interval_epoch: 1
  
checkpoint:
  save: True
  start_epoch: 1
  interval_epoch: 1

log:
  interval_iter: 10

test:
  #dataset: SIDD_benchmark
  dataset: SIDD_val

  dataset_args:
    crop_size: None # [64, 64]
    add_noise: gau-0.0025:1. # e.g.) None uni-15. gau-15. gau_blind-10.:50. poi_gau-10.:50.
    dataset_dir: 'K:\mydata\different private gradient\FasionMNIST_grad\val'

  add_con: 0
  floor: False
  #crop: None

  save_image: False
